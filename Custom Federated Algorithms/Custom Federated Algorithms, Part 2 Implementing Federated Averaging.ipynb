{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Custom Federated Algorithms, Part 2: Implementing Federated Averaging.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMv2ab5k0D0KJt4YT9259u6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"h7lcYSL20cx7"},"source":["# **Setting up environment**"]},{"cell_type":"code","metadata":{"id":"AMNE0DuqrCLX"},"source":["#@test {\"skip\": true}\n","!pip install --quiet --upgrade tensorflow-federated-nightly\n","!pip install --quiet --upgrade nest-asyncio\n","  \n","import nest_asyncio\n","nest_asyncio.apply()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvt84OoGvZHZ"},"source":["import collections\n","\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_federated as tff\n","\n","# TODO(b/148678573,b/148685415): must use the reference context because it\n","# supports unbounded references and tff.sequence_* intrinsics.\n","tff.backends.reference.set_reference_context()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xj_rcMzpvcz8"},"source":["@tff.federated_computation\n","def hello_world():\n","  return 'Hello, World!'\n","\n","hello_world()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5QLJv_YB0hhk"},"source":["# **Implementing Federated Averaging**"]},{"cell_type":"markdown","metadata":{"id":"m2pwrnKw0xPb"},"source":["\n","## **Preparing federated data sets**\n","\n","We have data from 10 users, and each of the users contributes knowledge how to recognize a different digit. This is about as non-i.i.d.as it gets."]},{"cell_type":"code","metadata":{"id":"MAhg91MC1AzW"},"source":["mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()                     # loading the standard MNIST data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhYBvCu61JBQ"},"source":["[(x.dtype, x.shape) for x in mnist_train]                                         # The data comes as Numpy arrays, one with images and another with digit labels, both with the first dimension going over the individual examples."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zFZ2yfQd7iwx"},"source":["A helper function that formats data in a way compatible with how we feed federated sequences into TFF computations, i.e., as a list of lists - the outer list ranging over the users (digits), the inner ones ranging over batches of data in each client's sequence. As is customary, each batch is structured as a pair of tensors named `x` and `y`, each with the leading batch dimension. "]},{"cell_type":"code","metadata":{"id":"FEfw8LNx1Q8s"},"source":["NUM_EXAMPLES_PER_USER = 1000\n","BATCH_SIZE = 100\n","\n","def get_data_for_digit(source, digit):\n","  output_sequence = []\n","  all_samples = [i for i, d in enumerate(source[1]) if d == digit]                # Enumerate() method adds a counter to an iterable and returns it in a form of enumerate object. This enumerate object can then be used directly in for loops or be converted into a list of tuples using list() method.\n","                                                                                  # all_samples contains counter (location) for all the samples with label \"digit\" as an enumerate\n","  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):    # Iterating over all samples with increament of BATCH_SIZE\n","    batch_samples = all_samples[i:i + BATCH_SIZE]                                 # Creating a list of samples in current batch\n","    output_sequence.append({                                                      # appends the information to \"output_sequence\"\n","        'x':\n","            np.array([source[0][i].flatten() / 255.0 for i in batch_samples],     # Under 'x', stores an array containing pixel information of all samples in batch_samples; flattens the 28x 28 matrix to a vector of 782 and normalizes values to lie in range on 0 to 1\n","                     dtype=np.float32),                                           # type casts all the value to float32\n","        'y':\n","            np.array([source[1][i] for i in batch_samples], dtype=np.int32)       # Under 'y', stores an array containg label information of all the samples in \"batch_samples\" and type cats it to int32\n","    })\n","  return output_sequence                                                          # output_sequence=[[batch1],[batch2],[batch3]...] for \"digit\"\n","                                                                                  # batch\"i\"=[pixel_vector1,pixel_vector2,...],[labe1, label2, ...]\n","federated_train_data = [get_data_for_digit(mnist_train, d) for d in range(10)]    # federated_train_data=[output_sequence for 0, output_sequence for 1,...]\n","                                                                                  # federated_train_data[a][b][c] contains batch_size elements where a=digit (client), b=batch number, c='x' or 'y'\n","federated_test_data = [get_data_for_digit(mnist_test, d) for d in range(10)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOmPh8mk_Aj8"},"source":["federated_train_data[5][-1]['y']                                                  # `Y` tensor in the last batch of data contributed by the fifth client (corresponding to digit `5`)."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TjKJJIc6DsV8"},"source":["# The image corresponding to the last element of that batch.\n","from matplotlib import pyplot as plt\n","\n","plt.imshow(federated_train_data[5][-1]['x'][-1].reshape(28, 28), cmap='gray')\n","plt.grid(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Sabv82kHONG"},"source":["## **On Combining TensorFlow and TFF**\n","\n","In this tutorial, for compactness we immediately decorate functions that\n","introduce TensorFlow logic with `tff.tf_computation`. However, for more complex logic, this is not the pattern we recommend. Debugging TensorFlow can already be a challenge, and debugging TensorFlow after it has been fully serialized and then re-imported necessarily loses some metadata and limits interactivity, making debugging even more of a challenge.\n","\n","Therefore, **we strongly recommend writing complex TF logic as stand-alone\n","Python functions** (that is, without `tff.tf_computation` decoration). This way the TensorFlow logic can be developed and tested using TF best practices and tools (like eager mode), before serializing the computation for TFF (e.g., by invoking `tff.tf_computation` with a Python function as the argument)."]},{"cell_type":"markdown","metadata":{"id":"IsgkZTvUgjD_"},"source":["## **Defining a loss function**"]},{"cell_type":"markdown","metadata":{"id":"7TTH8qLyhvkb"},"source":["### Defining the type of input as a TFF named tuple. "]},{"cell_type":"code","metadata":{"id":"LpgdKE95GuUU"},"source":["BATCH_SPEC = collections.OrderedDict(\n","    x=tf.TensorSpec(shape=[None, 784], dtype=tf.float32),                         # Since the size of data batches may vary, batch dimension is set to \n","                                                                                  #`None` to indicate that the size of this dimension is unknown.\n","    y=tf.TensorSpec(shape=[None], dtype=tf.int32))\n","BATCH_TYPE = tff.to_type(BATCH_SPEC)\n","\n","str(BATCH_TYPE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBuR6rN4hek4"},"source":["### Defining the model parameters\n","Parameters as a TFF named tuple of *weights* and *bias*."]},{"cell_type":"code","metadata":{"id":"yzvbF14wg_GI"},"source":["MODEL_SPEC = collections.OrderedDict(\n","    weights=tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n","    bias=tf.TensorSpec(shape=[10], dtype=tf.float32))\n","MODEL_TYPE = tff.to_type(MODEL_SPEC)\n","\n","print(MODEL_TYPE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4trtTGMlmMr6"},"source":["### Loss for the given model\n","\n","Note the usage of `@tf.function` decorator inside the `@tff.tf_computation` decorator. This allows to write TF using Python like semantics even though were inside a `tf.Graph` context created by the `tff.tf_computation` decorator."]},{"cell_type":"code","metadata":{"id":"LAt2-5xalsXu"},"source":["# NOTE: `forward_pass` is defined separately from `batch_loss` so that it can \n","# be later called from within another tf.function. Necessary because a\n","# @tf.function decorated method cannot invoke a @tff.tf_computation.\n","\n","@tf.function\n","def forward_pass(model, batch):\n","  predicted_y = tf.nn.softmax(                                                    # softmax on output\n","      tf.matmul(batch['x'], model['weights']) + model['bias'])                    # output=Wx+b\n","  return -tf.reduce_mean(\n","      tf.reduce_sum(\n","          tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1]))       \n","\n","@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n","def batch_loss(model, batch):\n","  return forward_pass(model, batch)\n","\n","str(batch_loss.type_signature)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1j34JDXvt_se"},"source":["### Constructing an initial model"]},{"cell_type":"code","metadata":{"id":"Jspe7U85nuNS"},"source":["initial_model = collections.OrderedDict(                                          # initaillizing all weights ans bais to 0\n","    weights=np.zeros([784, 10], dtype=np.float32),\n","    bias=np.zeros([10], dtype=np.float32))\n","\n","sample_batch = federated_train_data[5][-1]\n","\n","batch_loss(initial_model, sample_batch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HWZeqKOcvf4d"},"source":["The arguments of the call to `batch_loss` aren't simply passed to the body of that function.\n","\n","**What happens when we invoke `batch_loss`?**\n","\n","The Python body of `batch_loss` has already been traced and serialized  in the above cell where it was defined.  TFF acts as the caller to `batch_loss`\n","at the computation definition time, and as the target of invocation at the time `batch_loss` is invoked. In both roles, TFF serves as the bridge between TFF's abstract type system and Python representation types. At the invocation time, TFF will accept most standard Python container types (`dict`, `list`, `tuple`, `collections.namedtuple`, etc.) as concrete representations of abstract TFF tuples. Also, although as noted above, TFF computations formally only accept a single parameter, you can use the familiar Python call syntax with positional and/or keyword arguments in case where the type of the parameter is a tuple - it works as expected."]},{"cell_type":"markdown","metadata":{"id":"2Y2RFetqywHs"},"source":["### Gradient descent on a single batch\n","\n","Function to perform a single step of gradient descent. \n","\n","Note how in defining this function, we use `batch_loss` as a subcomponent. You can invoke a computation constructed with `tff.tf_computation` inside the body of another computation, though typically this is not necessary - as noted above, because serialization looses some debugging information, it is often preferable for more complex computations to write and test all the TensorFlow without the `tff.tf_computation` decorator."]},{"cell_type":"code","metadata":{"id":"xZr94F2hylSq"},"source":["@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n","def batch_train(initial_model, batch, learning_rate):                             # Define a group of model variables and set them to `initial_model`.\n","  model_vars = collections.OrderedDict([                                          # Must be defined outside the @tf.function.\n","      (name, tf.Variable(name=name, initial_value=value))                         # model_vars is an ordered dict. with same parameters as in initial_model and assigning same initial values\n","      for name, value in initial_model.items()])\n","  \n","  optimizer = tf.keras.optimizers.SGD(learning_rate)\n","\n","  @tf.function\n","  def _train_on_batch(model_vars, batch):                                         # Performs one step of gradient descent using loss from `batch_loss`.\n","    with tf.GradientTape() as tape:                                               # \"tape\" will watch the trainable parameters\n","      loss = forward_pass(model_vars, batch)                                      \n","    grads = tape.gradient(loss, model_vars)                                       # \"grads\" will contain gradient of \"loss\" with respect to \"model_vars\"\n","    optimizer.apply_gradients(                                                    # Applies gradient to variables, arguments are gradient and variables\n","        zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))                 # tf.nest.flatten() returns a flat list from a given nested structure, that is, if input is  [[a,b],[c],[d,e,f]] then output is [a,b,c,d,e,f]\n","    return model_vars\n","\n","  return _train_on_batch(model_vars, batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XeXQjhJA0UVi"},"source":["str(batch_train.type_signature)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nchku5xx0XtP"},"source":["When you invoke a Python function decorated with `tff.tf_computation` within the\n","body of another such function, the logic of the inner TFF computation is\n","embedded (essentially, inlined) in the logic of the outer one. As noted above,\n","if you are writing both computations, it is likely preferable to make the inner\n","function (`batch_loss` in this case) a regular Python or `tf.function` rather\n","than a `tff.tf_computation`. However, here we illustrate that calling one\n","`tff.tf_computation` inside another basically works as expected. This may be\n","necessary if, for example, you do not have the Python code defining\n","`batch_loss`, but only its serialized TFF representation.\n","\n","Now, let's apply this function a few times to the initial model to see whether\n","the loss decreases."]},{"cell_type":"code","metadata":{"id":"mB_C147c0ZWm"},"source":["model = initial_model\n","losses = []\n","for _ in range(5):\n","  model = batch_train(model, sample_batch, 0.1)\n","  losses.append(batch_loss(model, sample_batch))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwcH4ThH0bI1"},"source":["losses"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rdCRSjKCWjyu"},"source":["### Gradient descent on a sequence of local data\n","\n","`local_train` that consumes the entire sequence of all batches from one\n","user instead of just a single batch. The new computation will need to now\n","consume `tff.SequenceType(BATCH_TYPE)` instead of `BATCH_TYPE`."]},{"cell_type":"code","metadata":{"id":"hBzRroaHUgc8"},"source":["LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)                                    # Definng data type similar to that of BATCH_TYPE\n","\n","@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n","def local_train(initial_model, learning_rate, all_batches):\n","  @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n","  def batch_fn(model, batch):                                                     # Mapping function to apply to each batch.\n","    return batch_train(model, batch, learning_rate)                               # batch_train trains one batch one time\n","\n","  return tff.sequence_reduce(all_batches, initial_model, batch_fn)                # https://www.tensorflow.org/federated/api_docs/python/tff/sequence_reduce\n","                                                                                  # repeated application of function \"batch_fn\" on each element of \"all_batches\" to get reduced model parameters "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJCNVuA5Vs8t"},"source":["str(local_train.type_signature)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"seBMoo7QYscK"},"source":["There are quite a few details buried in this short section of code, let's go\n","over them one by one.\n","\n","*   We could have implemented this logic entirely in TensorFlow, relying on `tf.data.Dataset.reduce` to process the sequence similarly to how\n","we've done it earlier, we've opted this time to express the logic in the glue\n","language, as a `tff.federated_computation`. We've used the federated operator\n","`tff.sequence_reduce` to perform the reduction.\n","\n","  The operator `tff.sequence_reduce` is used similarly to\n","`tf.data.Dataset.reduce` but for the use inside federated computations. It is a template operator with a formal parameter 3-tuple:\n","  *   *sequence* of `T`-typed elements\n","  *   the initial state of  the reduction of some type `U`\n","  *   the *reduction operator* of type `(<U,T> -> U)` that alters the\n","state of the reduction by processing a single element. \n","\n","  The result is the final state of the reduction, after processing all elements in a sequential order. \n","\n","*   We have again used one computation (`batch_train`) as a\n","component within another (`local_train`), but not directly. We **can't use it as a reduction operator because it takes an additional parameter - the learning rate.**\n","\n","  To resolve this, we define an embedded federated computation `batch_fn` that binds to the `local_train`'s parameter `learning_rate` in its body. It is allowed for a child computation defined this way to capture a formal parameter of its parent as long as the child computation is not invoked outside the body of its parent. You can think of this pattern as an equivalent of `functools.partial` in Python.\n","\n","  The practical implication of capturing `learning_rate` this way is, of course, that the same learning rate value is used across all batches."]},{"cell_type":"code","metadata":{"id":"7S7uJgLPa_nl"},"source":["locally_trained_model = local_train(initial_model, 0.1, federated_train_data[5])\n","print(locally_trained_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7VoHMrJwtPNL"},"source":["## **Evaluation**"]},{"cell_type":"markdown","metadata":{"id":"hZJIHKBmbs6d"},"source":["### Local evaluation"]},{"cell_type":"code","metadata":{"id":"ydR2Ztrpb1k-"},"source":["@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n","def local_eval(model, all_batches):\n","                                                                                  # Computes sum of losses of all the batch \n","  return tff.sequence_sum(                                                        # Computes a sum of elements in a sequence.\n","      tff.sequence_map(                                                           # Maps a TFF sequence \"all_batches\" pointwise using given function\n","          tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),  # computes loss of each batch for the given \"model\"\n","          all_batches))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYVEwWteb3P4"},"source":["str(local_eval.type_signature)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"18orGk_Yeqy5"},"source":["@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n","def local_eval(model, all_batches):\n","  # TODO(b/120157713): Replace with `tff.sequence_average()` once implemented.\n","                                                                                  # Computes sum of losses of all the batch \n","  return tff.sequence_sum(                                                        # Computes a sum of elements in a sequence.\n","      tff.sequence_map(                                                           # Maps a TFF sequence \"all_batches\" pointwise using given function\n","          tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),  # computes loss of each batch for the given \"model\"\n","          all_batches))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h2VBzQq2hHqX"},"source":["1.   We have used two new federated operators for processing sequences:\n","  *  `tff.sequence_map` that takes a *mapping function* `T->U` and a *sequence* of `T`, and emits a sequence of `U` obtained by applying the mapping function pointwise\n","  *   `tff.sequence_sum` that just adds all the elements\n","\n","  Note that **we could have again used `tff.sequence_reduce`, but this wouldn't be the best choice - the reduction process is, by definition, sequential, whereas the mapping and sum can be computed in parallel.** \n","\n","2.   Just as in `local_train`, the component function we need\n","(`batch_loss`) takes more parameters than what the federated operator\n","(`tff.sequence_map`) expects, so we again define a partial, this time inline by directly wrapping a `lambda` as a `tff.federated_computation`. Using wrappers inline with a function as an argument is the recommended way to use\n","`tff.tf_computation` to embed TensorFlow logic in TFF."]},{"cell_type":"code","metadata":{"id":"p4I2sfFnkF4Q"},"source":["print('initial_model loss =', local_eval(initial_model,\n","                                         federated_train_data[5]))\n","print('locally_trained_model loss =',\n","      local_eval(locally_trained_model, federated_train_data[5]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtsxY67gkHsp"},"source":["print('initial_model loss =', local_eval(initial_model,\n","                                         federated_train_data[0]))\n","print('locally_trained_model loss =',\n","      local_eval(locally_trained_model, federated_train_data[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qca7mqLXkTwL"},"source":["Loss decreased the case of client 5 but not for client 0."]},{"cell_type":"markdown","metadata":{"id":"h_d9EvH_lidZ"},"source":["### Federated Evaluation\n","A pair of TFF types definitions for the model that originates at the server, and the data that remains on the clients."]},{"cell_type":"code","metadata":{"id":"UR1399GDnCFA"},"source":["SERVER_MODEL_TYPE = tff.type_at_server(MODEL_TYPE)\n","CLIENT_DATA_TYPE = tff.type_at_clients(LOCAL_DATA_TYPE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rnMQ6lYrnmCL"},"source":["Distribute the model to clients, let each client invoke\n","local evaluation on its local portion of data, and then average out the loss."]},{"cell_type":"code","metadata":{"id":"bjShRMahnrIE"},"source":["@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n","def federated_eval(model, data):\n","  return tff.federated_mean(\n","      tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))      # Maps the function parallely\n","                                                                                  # Local evaluation at each client\n","                                                                                  # tff.federated_broadcast() broadcasts a federated value from the tff.SERVER to the tff.CLIENTS."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"drHmpGI_pOKl"},"source":["1.   *let each client invoke local evaluation on its local portion of data* \n","\n","  `local_eval` has a type signature of the form `(<MODEL_TYPE, LOCAL_DATA_TYPE> ->float32)`. The federated operator `tff.federated_map` is a template that accepts as a parameter a 2-tuple:\n","  *   the *mapping function* of some type `T->U`\n","  *   a federated value of type `{T}@CLIENTS` (i.e., with member constituents of the same type as the parameter of the mapping function)\n","  *   returns a result of type `{U}@CLIENTS`.\n","\n","  The second argument should be of a federated type `{<MODEL_TYPE,\n","LOCAL_DATA_TYPE>}@CLIENTS`, i.e., in the nomenclature of the preceding sections, it should be a federated tuple. Each client should hold a full set of arguments for `local_eval` as a member consituent. Instead, we're feeding it a 2-element\n","Python `list`. What's happening here?\n","\n","Indeed, this is an example of an *implicit type cast* in TFF. Implicit casting is used scarcily at this point, but we plan to make it more pervasive in TFF as a way to minimize boilerplate.\n","\n","The implicit cast that's applied in this case is the equivalence between federated tuples of the form `{<X,Y>}@Z`, and tuples of federated values `<{X}@Z,{Y}@Z>`. While formally, these two are different type signatures, looking at it from the programmers's perspective, each device in `Z` holds two units of data `X` and `Y`. What happens here is not unlike `zip` in Python, and indeed, we offer an operator `tff.federated_zip` that allows you to perform such\n","conversions explicity. When the `tff.federated_map` encounters a tuple as a second argument, it simply invokes `tff.federated_zip` for you.\n","\n","Given the above, you should now be able to recognize the expression\n","`tff.federated_broadcast(model)` as representing a value of TFF type\n","`{MODEL_TYPE}@CLIENTS`, and `data` as a value of TFF type\n","`{LOCAL_DATA_TYPE}@CLIENTS` (or simply `CLIENT_DATA_TYPE`), the two getting filtered together through an implicit `tff.federated_zip` to form the second argument to `tff.federated_map`."]},{"cell_type":"code","metadata":{"id":"MEnxf6O5pSVL"},"source":["print('initial_model loss =', federated_eval(initial_model,\n","                                             federated_train_data))\n","print('locally_trained_model loss =',\n","      federated_eval(locally_trained_model, federated_train_data))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3UDwirkKs_Z5"},"source":["Indeed, as expected, the loss has increased. In order to improve the model for all users, we'll need to train in on everyone's data."]},{"cell_type":"markdown","metadata":{"id":"v9I2SNa3tBxs"},"source":["## **Federated training**\n","\n","The simplest way to implement federated training is to locally train, and then average the models. "]},{"cell_type":"code","metadata":{"id":"YuufZyW7tDya"},"source":["SERVER_FLOAT_TYPE = tff.type_at_server(tf.float32)\n","\n","\n","@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,\n","                           CLIENT_DATA_TYPE)\n","def federated_train(model, learning_rate, data):                                  # Locally trains data at each client and takes their average\n","  return tff.federated_mean(\n","      tff.federated_map(local_train, [\n","          tff.federated_broadcast(model),\n","          tff.federated_broadcast(learning_rate), data\n","      ]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UPPYy0g1tF0h"},"source":["Note that in the full-featured implementation of Federated Averaging provided by\n","`tff.learning`, rather than averaging the models, we prefer to average model\n","deltas, for a number of reasons, e.g., the ability to clip the update norms,\n","for compression, etc."]},{"cell_type":"code","metadata":{"id":"r4Rl6h3XtHgE"},"source":["model = initial_model\n","learning_rate = 0.1\n","for round_num in range(5):                                                        # running a few rounds of federated training\n","  model = federated_train(model, learning_rate, federated_train_data)\n","  learning_rate = learning_rate * 0.9                                             # Decreasing learning rate after each iteration\n","  loss = federated_eval(model, federated_train_data)\n","  print('round {}, loss={}'.format(round_num, loss))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OSa6no2ytJdA"},"source":["### Testing"]},{"cell_type":"code","metadata":{"id":"GmEgbYQ_tLHp"},"source":["print('initial_model test loss =',\n","      federated_eval(initial_model, federated_test_data))\n","print('trained_model test loss =', federated_eval(model, federated_test_data))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r3vuoADQoSb2"},"source":["# **Points to remember**\n","\n","\n","*  `tf.reduce_sum`, `tf.reduce_mean` is used for finding sum, mean in tensorf flow where computations and final values are stored at same place.\n","* `tff.federated_sum`, `tff.federated_mean` do the same for the values input from client but final values are stored at server.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_lijNUaEvGkn"},"source":["*   How can we find the time taken be each local training?\n","*   https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/learning/federated_averaging.py\n","\n","\n","\n"]}]}