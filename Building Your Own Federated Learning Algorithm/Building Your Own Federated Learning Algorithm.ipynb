{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Building Your Own Federated Learning Algorithm.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+iJJnOzMBkeL5gZa24ooi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YK-iZpIfNQWI"},"source":["# **Setting up environment**"]},{"cell_type":"code","metadata":{"id":"payKeiAfzAQU"},"source":["!pip install --quiet --upgrade tensorflow-federated-nightly\n","!pip install --quiet --upgrade nest-asyncio\n","\n","import nest_asyncio\n","nest_asyncio.apply()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"moOR2A6ZM03W"},"source":["import collections\n","import attr\n","import functools\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_federated as tff\n","\n","np.random.seed(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sH9uZA3ZNEyn"},"source":["# **Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"AbSFyP2RNsSU"},"source":["## Loading dataset"]},{"cell_type":"code","metadata":{"id":"2lu1VNXQM4VH"},"source":["emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A7cunrYjNwrE"},"source":["## Flattening data"]},{"cell_type":"code","metadata":{"id":"WWt-CdRrNVJu"},"source":["NUM_CLIENTS = 10\n","BATCH_SIZE = 20\n","\n","def preprocess(dataset):\n","  def batch_format_fn(element):\n","    return (tf.reshape(element['pixels'], [-1, 784]), \n","            tf.reshape(element['label'], [-1, 1]))\n","  return dataset.batch(BATCH_SIZE).map(batch_format_fn)                           # return a (features, label) tuple in a batch of BATCH_SIZE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpJbAVpwO8FS"},"source":["client_ids = np.random.choice(emnist_train.client_ids, size=NUM_CLIENTS,          # Randomly selets \"NUM_CLIENTS\" from the list of clients in  without replacement\n","                              replace=False)                                      # Probability of selection of each element can also be passed as an argument\n","\n","federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))  # Creates dataset for the selected clients\n","  for x in client_ids\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uKoUDAoFQ66R"},"source":["# **Model**\n"]},{"cell_type":"markdown","metadata":{"id":"RUfyl_McRyYA"},"source":["## Defining Keras model"]},{"cell_type":"code","metadata":{"id":"-Y-p5RGxRCPr"},"source":["def create_keras_model():\n","  return tf.keras.models.Sequential([                                             # Signal hidden layer sequential keras model\n","      tf.keras.layers.Input(shape=(784,)),\n","      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n","      tf.keras.layers.Softmax(),\n","  ])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-7f_muu_R5M7"},"source":["## Wrapping Keras model"]},{"cell_type":"code","metadata":{"id":"FSCrIYwwRhBS"},"source":["def model_fn():\n","  keras_model = create_keras_model()\n","  return tff.learning.from_keras_model(\n","      keras_model,\n","      input_spec=federated_train_data[0].element_spec,                            # Specification of input\n","      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QKI0PKpOSfZe"},"source":["TFF supports much more general models. These models have the following relevant attributes capturing the model weights:\n","\n","* **trainable_variables**: An iterable of the tensors corresponding to trainable layers.\n","* **non_trainable_variables**: An iterable of the tensors corresponding to non-trainable layers.\n"]},{"cell_type":"markdown","metadata":{"id":"1UuoBN9wSujj"},"source":["# **Building Federated Learning Algorithm**\n","\n","Other federated algorithms that do not fit neatly into this framework. For example, you may want to add regularization, clipping, or more complicated algorithms such as [federated GAN training](https://github.com/tensorflow/federated/tree/master/tensorflow_federated/python/research/gans). You may also be instead be interested in [federated analytics](https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html).\n","\n","For these more advanced algorithms, we'll have to write our own custom algorithm using TFF. In many cases, federated algorithms have 4 main components:\n","\n","1. A server-to-client broadcast step.\n","2. A local client update step.\n","3. A client-to-server upload step.\n","4. A server update step.\n","\n","In TFF, we generally represent federated algorithms as a `tff.templates.IterativeProcess`, which is referred to as an `IterativeProcess`. This is a class that contains `initialize` and `next` functions. Here, `initialize` is used to initialize the server, and `next` will perform one communication round of the federated algorithm. "]},{"cell_type":"code","metadata":{"id":"m_uAipPVSKEw"},"source":["def initialize_fn():\n","  model = model_fn()\n","  return model.trainable_variables"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xIQ4cklyVUGb"},"source":["def next_fn(server_weights, federated_dataset):\n","\n","  server_weights_at_client = broadcast(server_weights)                            # Broadcast the server weights to the clients.\n","  \n","  client_weights = client_update(federated_dataset, server_weights_at_client)     # Each client computes their updated weights.\n","  \n","  mean_client_weights = mean(client_weights)                                      # The server averages these updates.\n","  \n","  server_weights = server_update(mean_client_weights)                             # The server updates its model.\n","\n","  return server_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v3zvA_gqWCAA"},"source":["We'll focus on implementing these four components separately. We first focus on the parts that can be implemented in pure TensorFlow, namely the client and server update steps."]},{"cell_type":"markdown","metadata":{"id":"8Tx0SkIFWJoM"},"source":["## **TensorFlow Blocks**"]},{"cell_type":"markdown","metadata":{"id":"aDUynnArWVCz"},"source":["### **Client Update**\n","\n","We will use our `tff.learning.Model` to do client training in essentially the same way you would train a TensorFlow model. In particular, we will use `tf.GradientTape` to compute the gradient on batches of data, then apply these gradient using a `client_optimizer`. We focus only on the trainable weights."]},{"cell_type":"code","metadata":{"id":"_F7uOhB0WlRn"},"source":["@tf.function\n","def client_update(model, dataset, server_weights, client_optimizer):              # Performs training (using the server model weights) on the client's dataset.\n","  \n","  client_weights = model.trainable_variables                                      # Initialize the client model with the current server weights.\n","  \n","  tf.nest.map_structure(lambda x, y: x.assign(y),                                 # Assign the server weights to the client model by assigning each element of server_weights to client_weights\n","                        client_weights, server_weights)\n","                                                                                  # Use the client_optimizer to update the local model.\n","  for batch in dataset:                                                           # For each bacth in input \"Dataset\"\n","    with tf.GradientTape() as tape:\n","      outputs = model.forward_pass(batch)                                         # Compute a forward pass on the batch of data\n","\n","    grads = tape.gradient(outputs.loss, client_weights)                           # Compute the corresponding gradient of outputs.loss w.r.t. client_weights\n","    grads_and_vars = zip(grads, client_weights)                                   # Zips \"gradients\" and \"client_weights\"\n","\n","    client_optimizer.apply_gradients(grads_and_vars)                              # Apply the gradient using a client optimizer.\n","\n","  return client_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l9eRGGlDZbXi"},"source":["Parameter: Dataset\n","\n","Function: forward_pass(), apply_gradient()"]},{"cell_type":"markdown","metadata":{"id":"f_mX-nWb0NbK"},"source":["### **Server Update**\n","\n","We will implement \"vanilla\" federated averaging, replacing the server model weights by the average of the client model weights."]},{"cell_type":"code","metadata":{"id":"h3gH3zzi0jQ_"},"source":["@tf.function\n","def server_update(model, mean_client_weights):                                    # Updates the server model weights as the average of the client model weights.\n","  model_weights = model.trainable_variables\n","  \n","  tf.nest.map_structure(lambda x, y: x.assign(y),                                 # Assign the mean client weights to the server model.\n","                        model_weights, mean_client_weights)                       # tf.nest.map_structure() applies func to each entry in structure and returns a new structure.\n","  return model_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Luo_yIUw07D2"},"source":["Parameter: mean_client_weights"]},{"cell_type":"markdown","metadata":{"id":"Be40WYFH1D1n"},"source":["The snippet could be simplified by simply returning the `mean_client_weights`. However, more advanced implementations of Federated Averaging use `mean_client_weights` with more sophisticated techniques, such as momentum or adaptivity."]},{"cell_type":"markdown","metadata":{"id":"dxvgaopx3p9h"},"source":["## **TensorFlow Federeated Blocks**\n","\n","Remember that iterative process class contains `initialize` and `next` functions. For custom algorithm, we'll define an `initialize_fn` and `next_fn`. The `next_fn` will make use of the `client_update` and `server_update` we defined using pure TensorFlow code.\n","\n","However, in order to make our algorithm a federated computation, we will need both the `next_fn` and `initialize_fn` to each be a `tff.federated_computation`."]},{"cell_type":"markdown","metadata":{"id":"PZDGXipVIhRl"},"source":["### **`initialize_fn`**\n","\n","The initialize function will be quite simple: We will create a model using `model_fn`. However, remember that we must separate out our TensorFlow code using `tff.tf_computation`."]},{"cell_type":"code","metadata":{"id":"_pvChwchIutb"},"source":["@tff.tf_computation\n","def server_init():\n","  model = model_fn()\n","  return model.trainable_variables"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DTzcVAwqJwU3"},"source":["We can then pass this directly into a federated computation using `tff.federated_value`."]},{"cell_type":"code","metadata":{"id":"zarPOQQKJLj1"},"source":["@tff.federated_computation\n","def initialize_fn():\n","  return tff.federated_value(server_init(), tff.SERVER)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWZ1XLjXJzDF"},"source":["str(initialize_fn.type_signature)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"69xX4-aUKCGx"},"source":["### **`next_fn`**\n","\n","We now use our client and server update code to write the actual algorithm. We will first turn our `client_update` into a `tff.tf_computation` that accepts a client datasets and server weights, and outputs an updated client weights tensor."]},{"cell_type":"code","metadata":{"id":"e0XPfA5OJ9uh"},"source":["whimsy_model = model_fn()\n","tf_dataset_type = tff.SequenceType(whimsy_model.input_spec)                       # Dataset type\n","print(str(tf_dataset_type))\n","\n","model_weights_type = server_init.type_signature.result                            # Model weight type\n","print(str(model_weights_type))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"adfqxzEGUgXI"},"source":["###  **`client_update_fn`**\n"]},{"cell_type":"code","metadata":{"id":"5VB2gchOKgSJ"},"source":["@tff.tf_computation(tf_dataset_type, model_weights_type)\n","def client_update_fn(tf_dataset, server_weights):\n","  model = model_fn()\n","  client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n","  return client_update(model, tf_dataset, server_weights, client_optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nr-h-qfPVcb8"},"source":["### **`server_update_fn`**"]},{"cell_type":"code","metadata":{"id":"QvlGLRoNVbpg"},"source":["@tff.tf_computation(model_weights_type)\n","def server_update_fn(mean_client_weights):\n","  model = model_fn()\n","  return server_update(model, mean_client_weights)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hl8JEstfV1zf"},"source":["We need to create the `tff.federated_computation` that brings this all together. This function will accept two federated values, one corresponding to the server weights (with placement `tff.SERVER`), and the other corresponding to the client datasets (with placement `tff.CLIENTS`).\n","\n","Note that both these types were defined above! We simply need to give them the proper placement using `tff.FederatedType`."]},{"cell_type":"code","metadata":{"id":"giWp1AImV1Zs"},"source":["federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)\n","federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXeoxOtpVvNO"},"source":["@tff.federated_computation(federated_server_type, federated_dataset_type)\n","def next_fn(server_weights, federated_dataset):\n","  \n","  server_weights_at_client = tff.federated_broadcast(server_weights)              # Broadcast the server weights to the clients.\n","  \n","  client_weights = tff.federated_map(                                             # Each client computes their updated weights.\n","      client_update_fn, (federated_dataset, server_weights_at_client))\n","  \n","  mean_client_weights = tff.federated_mean(client_weights)                        # The server averages these updates.\n","\n","  server_weights = tff.federated_map(server_update_fn, mean_client_weights)       # The server updates its model.\n","\n","  return server_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vyaR0rIEciEQ"},"source":["We now have a `tff.federated_computation` for both the algorithm initialization, and for running one step of the algorithm. To finish our algorithm, we pass these into `tff.templates.IterativeProcess`."]},{"cell_type":"code","metadata":{"id":"g85wUUJycmGn"},"source":["federated_algorithm = tff.templates.IterativeProcess(\n","    initialize_fn=initialize_fn,\n","    next_fn=next_fn\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3t7N44xdNC8"},"source":["The type signature of the `initialize` and `next` functions of our iterative process."]},{"cell_type":"code","metadata":{"id":"xPkTBnrycnIh"},"source":["print(str(federated_algorithm.initialize.type_signature))\n","print(str(federated_algorithm.next.type_signature))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ny57AqOdSOM"},"source":["`federated_algorithm.initialize` is a no-arg function that returns a single-layer model (with a 784-by-10 weight matrix, and 10 bias units).\n","\n","`federated_algorithm.next` accepts a server model and client data, and returns an updated server model."]},{"cell_type":"markdown","metadata":{"id":"O4kq6JgceXz-"},"source":["# **Evaluating Algorithm**"]},{"cell_type":"code","metadata":{"id":"gqsOW72sdI1Q"},"source":["central_emnist_test = emnist_test.create_tf_dataset_from_all_clients().take(1000) # Taking only 1000 samples\n","central_emnist_test = preprocess(central_emnist_test)                             # Preprocessing test dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mxI0oBI6gkbx"},"source":["## **Evaluation on test dataset**"]},{"cell_type":"code","metadata":{"id":"ckG5OcRGgjyp"},"source":["def evaluate(server_state):\n","  keras_model = create_keras_model()                                              # Creates Keras mode\n","  keras_model.compile(                                                            # Configures the model for training\n","      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  \n","  )\n","  keras_model.set_weights(server_state)                                           # Sets the weights of model same as the server_state\n","  keras_model.evaluate(central_emnist_test)                                       # Returns the loss value & metrics values for the model in test mode.\n","                                                                                  # Computation is done in batch, if batch size not secified, 32 is default value"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HXpk_fhSpYq-"},"source":["Initializing algorithma nd testing on test dataset."]},{"cell_type":"code","metadata":{"id":"Qg-YljHEo9bG"},"source":["server_state = federated_algorithm.initialize()\n","evaluate(server_state)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-BZMnFW2pnaG"},"source":["Training few rounds"]},{"cell_type":"code","metadata":{"id":"7kX-JjFopqtZ"},"source":["for round in range(15):\n","  server_state = federated_algorithm.next(server_state, federated_train_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iawhNljhpjMc"},"source":["evaluate(server_state)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pv6IQRKwqZPl"},"source":["# **Challenge:**\n","\n","1. Implement a version of `server_update` that updates the server weights to be the midpoint of model_weights and mean_client_weights. (Note: This kind of \"midpoint\" approach is analogous to recent work on the [Lookahead optimizer](https://arxiv.org/abs/1907.08610)!).  \n","2. Add [gradient clipping](https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48) to the `client_update` function.\n","3. Implement Federated Averaging with learning rate decay on the clients.\n","  \n","  We could have the server store and broadcast more data. For example, the server could also store the client learning rate, and make it decay over time! Note that this will require changes to the type signatures used in the `tff.tf_computation` calls above.\n","\n","For ideas (including the answer to the harder challenge above) you can see the source-code for [`tff.learning.build_federated_averaging_process`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/build_federated_averaging_process), or check out various [research projects](https://github.com/google-research/federated) using TFF.\n"]}]}