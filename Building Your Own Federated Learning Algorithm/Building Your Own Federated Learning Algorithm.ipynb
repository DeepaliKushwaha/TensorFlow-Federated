{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Building Your Own Federated Learning Algorithm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+iJJnOzMBkeL5gZa24ooi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YK-iZpIfNQWI"},"source":["# **Setting up environment**"]},{"cell_type":"code","metadata":{"id":"payKeiAfzAQU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623348926077,"user_tz":-330,"elapsed":75831,"user":{"displayName":"Deepali Kushwaha","photoUrl":"","userId":"16066864187469852350"}},"outputId":"214b5b71-d081-45a5-d9b1-63a30cf6b8bc"},"source":["!pip install --quiet --upgrade tensorflow-federated-nightly\n","!pip install --quiet --upgrade nest-asyncio\n","\n","import nest_asyncio\n","nest_asyncio.apply()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 454.9MB 37kB/s \n","\u001b[K     |████████████████████████████████| 5.5MB 38.1MB/s \n","\u001b[K     |████████████████████████████████| 471kB 49.4MB/s \n","\u001b[K     |████████████████████████████████| 1.3MB 24.9MB/s \n","\u001b[31mERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.37.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.5.0 has requirement keras-nightly~=2.5.0.dev, but you'll have keras-nightly 2.6.0.dev2021061000 which is incompatible.\u001b[0m\n","\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pymc3 3.11.2 has requirement cachetools>=4.2.1, but you'll have cachetools 3.1.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"moOR2A6ZM03W"},"source":["import collections\n","import attr\n","import functools\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_federated as tff\n","\n","np.random.seed(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sH9uZA3ZNEyn"},"source":["# **Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"AbSFyP2RNsSU"},"source":["## Loading dataset"]},{"cell_type":"code","metadata":{"id":"2lu1VNXQM4VH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623348995552,"user_tz":-330,"elapsed":64596,"user":{"displayName":"Deepali Kushwaha","photoUrl":"","userId":"16066864187469852350"}},"outputId":"44e8be16-e745-4f80-dae1-f120aa64a8be"},"source":["emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading emnist_all.sqlite.lzma: 100%|██████████| 170507172/170507172 [00:59<00:00, 2443459.93it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"A7cunrYjNwrE"},"source":["## Flattening data"]},{"cell_type":"code","metadata":{"id":"WWt-CdRrNVJu"},"source":["NUM_CLIENTS = 10\n","BATCH_SIZE = 20\n","\n","def preprocess(dataset):\n","  def batch_format_fn(element):\n","    return (tf.reshape(element['pixels'], [-1, 784]), \n","            tf.reshape(element['label'], [-1, 1]))\n","  return dataset.batch(BATCH_SIZE).map(batch_format_fn)                           # return a (features, label) tuple in a batch of BATCH_SIZE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpJbAVpwO8FS"},"source":["client_ids = np.random.choice(emnist_train.client_ids, size=NUM_CLIENTS,          # Randomly selets \"NUM_CLIENTS\" from the list of clients in  without replacement\n","                              replace=False)                                      # Probability of selection of each element can also be passed as an argument\n","\n","federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))  # Creates dataset for the selected clients\n","  for x in client_ids\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uKoUDAoFQ66R"},"source":["# **Model**\n"]},{"cell_type":"markdown","metadata":{"id":"RUfyl_McRyYA"},"source":["## Defining Keras model"]},{"cell_type":"code","metadata":{"id":"-Y-p5RGxRCPr"},"source":["def create_keras_model():\n","  return tf.keras.models.Sequential([                                             # Signal hidden layer sequential keras model\n","      tf.keras.layers.Input(shape=(784,)),\n","      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n","      tf.keras.layers.Softmax(),\n","  ])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-7f_muu_R5M7"},"source":["## Wrapping Keras model"]},{"cell_type":"code","metadata":{"id":"FSCrIYwwRhBS"},"source":["def model_fn():\n","  keras_model = create_keras_model()\n","  return tff.learning.from_keras_model(\n","      keras_model,\n","      input_spec=federated_train_data[0].element_spec,                            # Specification of input\n","      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QKI0PKpOSfZe"},"source":["TFF supports much more general models. These models have the following relevant attributes capturing the model weights:\n","\n","* **trainable_variables**: An iterable of the tensors corresponding to trainable layers.\n","* **non_trainable_variables**: An iterable of the tensors corresponding to non-trainable layers.\n"]},{"cell_type":"markdown","metadata":{"id":"1UuoBN9wSujj"},"source":["# **Building Federated Learning Algorithm**\n","\n","Other federated algorithms that do not fit neatly into this framework. For example, you may want to add regularization, clipping, or more complicated algorithms such as [federated GAN training](https://github.com/tensorflow/federated/tree/master/tensorflow_federated/python/research/gans). You may also be instead be interested in [federated analytics](https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html).\n","\n","For these more advanced algorithms, we'll have to write our own custom algorithm using TFF. In many cases, federated algorithms have 4 main components:\n","\n","1. A server-to-client broadcast step.\n","2. A local client update step.\n","3. A client-to-server upload step.\n","4. A server update step.\n","\n","In TFF, we generally represent federated algorithms as a `tff.templates.IterativeProcess`, which is referred to as an `IterativeProcess`. This is a class that contains `initialize` and `next` functions. Here, `initialize` is used to initialize the server, and `next` will perform one communication round of the federated algorithm. "]},{"cell_type":"code","metadata":{"id":"m_uAipPVSKEw"},"source":["def initialize_fn():\n","  model = model_fn()\n","  return model.trainable_variables"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xIQ4cklyVUGb"},"source":["def next_fn(server_weights, federated_dataset):\n","\n","  server_weights_at_client = broadcast(server_weights)                            # Broadcast the server weights to the clients.\n","  \n","  client_weights = client_update(federated_dataset, server_weights_at_client)     # Each client computes their updated weights.\n","  \n","  mean_client_weights = mean(client_weights)                                      # The server averages these updates.\n","  \n","  server_weights = server_update(mean_client_weights)                             # The server updates its model.\n","\n","  return server_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v3zvA_gqWCAA"},"source":["We'll focus on implementing these four components separately. We first focus on the parts that can be implemented in pure TensorFlow, namely the client and server update steps."]},{"cell_type":"markdown","metadata":{"id":"8Tx0SkIFWJoM"},"source":["## **TensorFlow Blocks**"]},{"cell_type":"markdown","metadata":{"id":"aDUynnArWVCz"},"source":["### **Client Update**\n","\n","We will use our `tff.learning.Model` to do client training in essentially the same way you would train a TensorFlow model. In particular, we will use `tf.GradientTape` to compute the gradient on batches of data, then apply these gradient using a `client_optimizer`. We focus only on the trainable weights."]},{"cell_type":"code","metadata":{"id":"_F7uOhB0WlRn"},"source":["@tf.function\n","def client_update(model, dataset, server_weights, client_optimizer):              # Performs training (using the server model weights) on the client's dataset.\n","  \n","  client_weights = model.trainable_variables                                      # Initialize the client model with the current server weights.\n","  \n","  tf.nest.map_structure(lambda x, y: x.assign(y),                                 # Assign the server weights to the client model by assigning each element of server_weights to client_weights\n","                        client_weights, server_weights)\n","                                                                                  # Use the client_optimizer to update the local model.\n","  for batch in dataset:                                                           # For each bacth in input \"Dataset\"\n","    with tf.GradientTape() as tape:\n","      outputs = model.forward_pass(batch)                                         # Compute a forward pass on the batch of data\n","\n","    grads = tape.gradient(outputs.loss, client_weights)                           # Compute the corresponding gradient of outputs.loss w.r.t. client_weights\n","    grads_and_vars = zip(grads, client_weights)                                   # Zips \"gradients\" and \"client_weights\"\n","\n","    client_optimizer.apply_gradients(grads_and_vars)                              # Apply the gradient using a client optimizer.\n","\n","  return client_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l9eRGGlDZbXi"},"source":["Parameter: Dataset\n","\n","Function: forward_pass(), apply_gradient()"]},{"cell_type":"markdown","metadata":{"id":"f_mX-nWb0NbK"},"source":["### **Server Update**\n","\n","We will implement \"vanilla\" federated averaging, replacing the server model weights by the average of the client model weights."]},{"cell_type":"code","metadata":{"id":"h3gH3zzi0jQ_"},"source":["@tf.function\n","def server_update(model, mean_client_weights):                                    # Updates the server model weights as the average of the client model weights.\n","  model_weights = model.trainable_variables\n","  \n","  tf.nest.map_structure(lambda x, y: x.assign(y),                                 # Assign the mean client weights to the server model.\n","                        model_weights, mean_client_weights)                       # tf.nest.map_structure() applies func to each entry in structure and returns a new structure.\n","  return model_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Luo_yIUw07D2"},"source":["Parameter: mean_client_weights"]},{"cell_type":"markdown","metadata":{"id":"Be40WYFH1D1n"},"source":["The snippet could be simplified by simply returning the `mean_client_weights`. However, more advanced implementations of Federated Averaging use `mean_client_weights` with more sophisticated techniques, such as momentum or adaptivity."]},{"cell_type":"markdown","metadata":{"id":"dxvgaopx3p9h"},"source":["## **TensorFlow Federeated Blocks**\n","\n","Remember that iterative process class contains `initialize` and `next` functions. For custom algorithm, we'll define an `initialize_fn` and `next_fn`. The `next_fn` will make use of the `client_update` and `server_update` we defined using pure TensorFlow code.\n","\n","However, in order to make our algorithm a federated computation, we will need both the `next_fn` and `initialize_fn` to each be a `tff.federated_computation`."]},{"cell_type":"markdown","metadata":{"id":"PZDGXipVIhRl"},"source":["### **`initialize_fn`**\n","\n","The initialize function will be quite simple: We will create a model using `model_fn`. However, remember that we must separate out our TensorFlow code using `tff.tf_computation`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_pvChwchIutb","executionInfo":{"status":"ok","timestamp":1623348996197,"user_tz":-330,"elapsed":653,"user":{"displayName":"Deepali Kushwaha","photoUrl":"","userId":"16066864187469852350"}},"outputId":"fabcec29-9226-45b1-f268-6c7388b349d2"},"source":["@tff.tf_computation\n","def server_init():\n","  model = model_fn()\n","  return model.trainable_variables"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"DTzcVAwqJwU3"},"source":["We can then pass this directly into a federated computation using `tff.federated_value`."]},{"cell_type":"code","metadata":{"id":"zarPOQQKJLj1"},"source":["@tff.federated_computation\n","def initialize_fn():\n","  return tff.federated_value(server_init(), tff.SERVER)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"OWZ1XLjXJzDF","executionInfo":{"status":"ok","timestamp":1623348996203,"user_tz":-330,"elapsed":45,"user":{"displayName":"Deepali Kushwaha","photoUrl":"","userId":"16066864187469852350"}},"outputId":"8a127e42-fd1b-4e3c-e897-2f7fe49d1ec2"},"source":["str(initialize_fn.type_signature)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'( -> <float32[784,10],float32[10]>@SERVER)'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"69xX4-aUKCGx"},"source":["### **`next_fn`**\n","\n","We now use our client and server update code to write the actual algorithm. We will first turn our `client_update` into a `tff.tf_computation` that accepts a client datasets and server weights, and outputs an updated client weights tensor."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e0XPfA5OJ9uh","executionInfo":{"status":"ok","timestamp":1623348996204,"user_tz":-330,"elapsed":35,"user":{"displayName":"Deepali Kushwaha","photoUrl":"","userId":"16066864187469852350"}},"outputId":"1ae8054a-b3b3-4b4b-ee24-ed8163126c75"},"source":["whimsy_model = model_fn()\n","tf_dataset_type = tff.SequenceType(whimsy_model.input_spec)                       # Dataset type\n","print(str(tf_dataset_type))\n","\n","model_weights_type = server_init.type_signature.result                            # Model weight type\n","print(str(model_weights_type))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stderr"},{"output_type":"stream","text":["<float32[?,784],int32[?,1]>*\n","<float32[784,10],float32[10]>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"adfqxzEGUgXI"},"source":["###  **`client_update_fn`**\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5VB2gchOKgSJ","executionInfo":{"status":"ok","timestamp":1623348997911,"user_tz":-330,"elapsed":1734,"user":{"displayName":"Deepali Kushwaha","photoUrl":"","userId":"16066864187469852350"}},"outputId":"a82c968b-a014-4173-a4c5-88fdda36b2ea"},"source":["@tff.tf_computation(tf_dataset_type, model_weights_type)\n","def client_update_fn(tf_dataset, server_weights):\n","  model = model_fn()\n","  client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n","  return client_update(model, tf_dataset, server_weights, client_optimizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Nr-h-qfPVcb8"},"source":["### **`server_update_fn`**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvlGLRoNVbpg","executionInfo":{"status":"ok","timestamp":1623348997920,"user_tz":-330,"elapsed":35,"user":{"displayName":"Deepali Kushwaha","photoUrl":"","userId":"16066864187469852350"}},"outputId":"98a80024-cf1b-413d-f92d-7979d7649276"},"source":["@tff.tf_computation(model_weights_type)\n","def server_update_fn(mean_client_weights):\n","  model = model_fn()\n","  return server_update(model, mean_client_weights)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"hl8JEstfV1zf"},"source":["We need to create the `tff.federated_computation` that brings this all together. This function will accept two federated values, one corresponding to the server weights (with placement `tff.SERVER`), and the other corresponding to the client datasets (with placement `tff.CLIENTS`).\n","\n","Note that both these types were defined above! We simply need to give them the proper placement using `tff.FederatedType`."]},{"cell_type":"code","metadata":{"id":"giWp1AImV1Zs"},"source":["federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)\n","federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXeoxOtpVvNO"},"source":["@tff.federated_computation(federated_server_type, federated_dataset_type)\n","def next_fn(server_weights, federated_dataset):\n","  \n","  server_weights_at_client = tff.federated_broadcast(server_weights)              # Broadcast the server weights to the clients.\n","  \n","  client_weights = tff.federated_map(                                             # Each client computes their updated weights.\n","      client_update_fn, (federated_dataset, server_weights_at_client))\n","  \n","  mean_client_weights = tff.federated_mean(client_weights)                        # The server averages these updates.\n","\n","  server_weights = tff.federated_map(server_update_fn, mean_client_weights)       # The server updates its model.\n","\n","  return server_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vyaR0rIEciEQ"},"source":["We now have a `tff.federated_computation` for both the algorithm initialization, and for running one step of the algorithm. To finish our algorithm, we pass these into `tff.templates.IterativeProcess`."]},{"cell_type":"code","metadata":{"id":"g85wUUJycmGn"},"source":["federated_algorithm = tff.templates.IterativeProcess(\n","    initialize_fn=initialize_fn,\n","    next_fn=next_fn\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3t7N44xdNC8"},"source":["The type signature of the `initialize` and `next` functions of our iterative process."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xPkTBnrycnIh","executionInfo":{"status":"ok","timestamp":1623348997923,"user_tz":-330,"elapsed":23,"user":{"displayName":"Deepali Kushwaha","photoUrl":"","userId":"16066864187469852350"}},"outputId":"845c4d5b-77cb-4711-b2bf-b668842942bf"},"source":["print(str(federated_algorithm.initialize.type_signature))\n","print(str(federated_algorithm.next.type_signature))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["( -> <float32[784,10],float32[10]>@SERVER)\n","(<server_weights=<float32[784,10],float32[10]>@SERVER,federated_dataset={<float32[?,784],int32[?,1]>*}@CLIENTS> -> <float32[784,10],float32[10]>@SERVER)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2ny57AqOdSOM"},"source":["`federated_algorithm.initialize` is a no-arg function that returns a single-layer model (with a 784-by-10 weight matrix, and 10 bias units).\n","\n","`federated_algorithm.next` accepts a server model and client data, and returns an updated server model."]},{"cell_type":"markdown","metadata":{"id":"O4kq6JgceXz-"},"source":["# **Evaluating Algorithm**"]},{"cell_type":"code","metadata":{"id":"gqsOW72sdI1Q"},"source":["central_emnist_test = emnist_test.create_tf_dataset_from_all_clients().take(1000) # Taking only 1000 samples\n","central_emnist_test = preprocess(central_emnist_test)                             # Preprocessing test dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mxI0oBI6gkbx"},"source":["## **Evaluation on test dataset**"]},{"cell_type":"code","metadata":{"id":"ckG5OcRGgjyp"},"source":["def evaluate(server_state):\n","  keras_model = create_keras_model()                                              # Creates Keras mode\n","  keras_model.compile(                                                            # Configures the model for training\n","      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  \n","  )\n","  keras_model.set_weights(server_state)                                           # Sets the weights of model same as the server_state\n","  keras_model.evaluate(central_emnist_test)                                       # Returns the loss value & metrics values for the model in test mode.\n","                                                                                  # Computation is done in batch, if batch size not secified, 32 is default value"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HXpk_fhSpYq-"},"source":["Initializing algorithma nd testing on test dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qg-YljHEo9bG","executionInfo":{"status":"ok","timestamp":1623348999196,"user_tz":-330,"elapsed":655,"user":{"displayName":"Deepali Kushwaha","photoUrl":"","userId":"16066864187469852350"}},"outputId":"c8a3258f-c558-4694-a8bd-84c7a70f64be"},"source":["server_state = federated_algorithm.initialize()\n","evaluate(server_state)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stderr"},{"output_type":"stream","text":["50/50 [==============================] - 1s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.1120\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-BZMnFW2pnaG"},"source":["Training few rounds"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7kX-JjFopqtZ","executionInfo":{"status":"ok","timestamp":1623349021867,"user_tz":-330,"elapsed":22686,"user":{"displayName":"Deepali Kushwaha","photoUrl":"","userId":"16066864187469852350"}},"outputId":"648be6c3-72a6-4aed-abd8-3cbe4890fec3"},"source":["for round in range(15):\n","  server_state = federated_algorithm.next(server_state, federated_train_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:60: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:60: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iawhNljhpjMc","executionInfo":{"status":"ok","timestamp":1623349022802,"user_tz":-330,"elapsed":971,"user":{"displayName":"Deepali Kushwaha","photoUrl":"","userId":"16066864187469852350"}},"outputId":"6045b8b3-b53f-4c9d-885a-e9d2063f5dd2"},"source":["evaluate(server_state)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"],"name":"stderr"},{"output_type":"stream","text":["50/50 [==============================] - 0s 4ms/step - loss: 2.5746 - sparse_categorical_accuracy: 0.0930\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pv6IQRKwqZPl"},"source":["# **Challenge:**\n","\n","1. Implement a version of `server_update` that updates the server weights to be the midpoint of model_weights and mean_client_weights. (Note: This kind of \"midpoint\" approach is analogous to recent work on the [Lookahead optimizer](https://arxiv.org/abs/1907.08610)!).  \n","2. Add [gradient clipping](https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48) to the `client_update` function.\n","3. Implement Federated Averaging with learning rate decay on the clients.\n","  \n","  We could have the server store and broadcast more data. For example, the server could also store the client learning rate, and make it decay over time! Note that this will require changes to the type signatures used in the `tff.tf_computation` calls above.\n","\n","For ideas (including the answer to the harder challenge above) you can see the source-code for [`tff.learning.build_federated_averaging_process`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/build_federated_averaging_process), or check out various [research projects](https://github.com/google-research/federated) using TFF.\n"]}]}