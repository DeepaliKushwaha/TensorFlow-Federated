{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Building Your Own Federated Learning Algorithm.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNZG5dUjTS7kuVBRyOwfeq6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YK-iZpIfNQWI"},"source":["# **Setting up environment**"]},{"cell_type":"code","metadata":{"id":"payKeiAfzAQU"},"source":["!pip install --quiet --upgrade tensorflow-federated-nightly\n","!pip install --quiet --upgrade nest-asyncio\n","\n","import nest_asyncio\n","nest_asyncio.apply()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"moOR2A6ZM03W"},"source":["import collections\n","import attr\n","import functools\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_federated as tff\n","\n","np.random.seed(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sH9uZA3ZNEyn"},"source":["# **Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"AbSFyP2RNsSU"},"source":["## Loading dataset"]},{"cell_type":"code","metadata":{"id":"2lu1VNXQM4VH"},"source":["emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A7cunrYjNwrE"},"source":["## Flattening data"]},{"cell_type":"code","metadata":{"id":"WWt-CdRrNVJu"},"source":["NUM_CLIENTS = 10\n","BATCH_SIZE = 20\n","\n","def preprocess(dataset):\n","  def batch_format_fn(element):\n","    return (tf.reshape(element['pixels'], [-1, 784]), \n","            tf.reshape(element['label'], [-1, 1]))\n","  return dataset.batch(BATCH_SIZE).map(batch_format_fn)                           # return a (features, label) tuple in a batch of BATCH_SIZE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpJbAVpwO8FS"},"source":["client_ids = np.random.choice(emnist_train.client_ids, size=NUM_CLIENTS,          # Randomly selets \"NUM_CLIENTS\" from the list of clients in  without replacement\n","                              replace=False)                                      # Probability of selection of each element can also be passed as an argument\n","\n","federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))  # Creates dataset for the selected clients\n","  for x in client_ids\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uKoUDAoFQ66R"},"source":["# **Model**\n"]},{"cell_type":"markdown","metadata":{"id":"RUfyl_McRyYA"},"source":["## Defining Keras model"]},{"cell_type":"code","metadata":{"id":"-Y-p5RGxRCPr"},"source":["def create_keras_model():\n","  return tf.keras.models.Sequential([                                             # Signal hidden layer sequential keras model\n","      tf.keras.layers.Input(shape=(784,)),\n","      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n","      tf.keras.layers.Softmax(),\n","  ])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-7f_muu_R5M7"},"source":["## Wrapping Keras model"]},{"cell_type":"code","metadata":{"id":"FSCrIYwwRhBS"},"source":["def model_fn():\n","  keras_model = create_keras_model()\n","  return tff.learning.from_keras_model(\n","      keras_model,\n","      input_spec=federated_train_data[0].element_spec,                            # Specification of input\n","      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1UuoBN9wSujj"},"source":["# **Building Federated Learning Algorithm**"]},{"cell_type":"code","metadata":{"id":"m_uAipPVSKEw"},"source":["def initialize_fn():\n","  model = model_fn()\n","  return model.trainable_variables"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xIQ4cklyVUGb"},"source":["def next_fn(server_weights, federated_dataset):\n","\n","  server_weights_at_client = broadcast(server_weights)                            # Broadcast the server weights to the clients.\n","  \n","  client_weights = client_update(federated_dataset, server_weights_at_client)     # Each client computes their updated weights.\n","  \n","  mean_client_weights = mean(client_weights)                                      # The server averages these updates.\n","  \n","  server_weights = server_update(mean_client_weights)                             # The server updates its model.\n","\n","  return server_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Tx0SkIFWJoM"},"source":["## **TensorFlow Blocks**"]},{"cell_type":"markdown","metadata":{"id":"aDUynnArWVCz"},"source":["### **Client Update**\n"]},{"cell_type":"code","metadata":{"id":"_F7uOhB0WlRn"},"source":["@tf.function\n","def client_update(model, dataset, server_weights, client_optimizer):              # Performs training (using the server model weights) on the client's dataset.\n","  \n","  client_weights = model.trainable_variables                                      # Initialize the client model with the current server weights.\n","  \n","  tf.nest.map_structure(lambda x, y: x.assign(y),                                 # Assign the server weights to the client model by assigning each element of server_weights to client_weights\n","                        client_weights, server_weights)\n","                                                                                  # Use the client_optimizer to update the local model.\n","  for batch in dataset:                                                           # For each bacth in input \"Dataset\"\n","    with tf.GradientTape() as tape:\n","      outputs = model.forward_pass(batch)                                         # Compute a forward pass on the batch of data\n","\n","    grads = tape.gradient(outputs.loss, client_weights)                           # Compute the corresponding gradient of outputs.loss w.r.t. client_weights\n","    grads_and_vars = zip(grads, client_weights)                                   # Zips \"gradients\" and \"client_weights\"\n","\n","    client_optimizer.apply_gradients(grads_and_vars)                              # Apply the gradient using a client optimizer.\n","\n","  return client_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f_mX-nWb0NbK"},"source":["### **Server Update**"]},{"cell_type":"code","metadata":{"id":"h3gH3zzi0jQ_"},"source":["@tf.function\n","def server_update(model, mean_client_weights):                                    # Updates the server model weights as the average of the client model weights.\n","  model_weights = model.trainable_variables\n","  \n","  tf.nest.map_structure(lambda x, y: x.assign(y),                                 # Assign the mean client weights to the server model.\n","                        model_weights, mean_client_weights)                       # tf.nest.map_structure() applies func to each entry in structure and returns a new structure.\n","  return model_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxvgaopx3p9h"},"source":["## **TensorFlow Federeated Blocks**"]},{"cell_type":"markdown","metadata":{"id":"PZDGXipVIhRl"},"source":["### **`initialize_fn`**"]},{"cell_type":"code","metadata":{"id":"_pvChwchIutb"},"source":["@tff.tf_computation\n","def server_init():\n","  model = model_fn()\n","  return model.trainable_variables"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zarPOQQKJLj1"},"source":["@tff.federated_computation\n","def initialize_fn():\n","  return tff.federated_value(server_init(), tff.SERVER)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWZ1XLjXJzDF"},"source":["str(initialize_fn.type_signature)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"69xX4-aUKCGx"},"source":["### **`next_fn`**"]},{"cell_type":"code","metadata":{"id":"e0XPfA5OJ9uh"},"source":["whimsy_model = model_fn()\n","tf_dataset_type = tff.SequenceType(whimsy_model.input_spec)                       # Dataset type\n","print(str(tf_dataset_type))\n","\n","model_weights_type = server_init.type_signature.result                            # Model weight type\n","print(str(model_weights_type))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"adfqxzEGUgXI"},"source":["###  **`client_update_fn`**\n"]},{"cell_type":"code","metadata":{"id":"5VB2gchOKgSJ"},"source":["@tff.tf_computation(tf_dataset_type, model_weights_type)\n","def client_update_fn(tf_dataset, server_weights):\n","  model = model_fn()\n","  client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n","  return client_update(model, tf_dataset, server_weights, client_optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nr-h-qfPVcb8"},"source":["### **`server_update_fn`**"]},{"cell_type":"code","metadata":{"id":"QvlGLRoNVbpg"},"source":["@tff.tf_computation(model_weights_type)\n","def server_update_fn(mean_client_weights):\n","  model = model_fn()\n","  return server_update(model, mean_client_weights)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"giWp1AImV1Zs"},"source":["federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)\n","federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXeoxOtpVvNO"},"source":["@tff.federated_computation(federated_server_type, federated_dataset_type)\n","def next_fn(server_weights, federated_dataset):\n","  \n","  server_weights_at_client = tff.federated_broadcast(server_weights)              # Broadcast the server weights to the clients.\n","  \n","  client_weights = tff.federated_map(                                             # Each client computes their updated weights.\n","      client_update_fn, (federated_dataset, server_weights_at_client))\n","  \n","  mean_client_weights = tff.federated_mean(client_weights)                        # The server averages these updates.\n","\n","  server_weights = tff.federated_map(server_update_fn, mean_client_weights)       # The server updates its model.\n","\n","  return server_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g85wUUJycmGn"},"source":["federated_algorithm = tff.templates.IterativeProcess(\n","    initialize_fn=initialize_fn,\n","    next_fn=next_fn\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xPkTBnrycnIh"},"source":["print(str(federated_algorithm.initialize.type_signature))\n","print(str(federated_algorithm.next.type_signature))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O4kq6JgceXz-"},"source":["# **Evaluating Algorithm**"]},{"cell_type":"code","metadata":{"id":"gqsOW72sdI1Q"},"source":["central_emnist_test = emnist_test.create_tf_dataset_from_all_clients().take(1000) # Taking only 1000 samples\n","central_emnist_test = preprocess(central_emnist_test)                             # Preprocessing test dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mxI0oBI6gkbx"},"source":["## **Evaluation on test dataset**"]},{"cell_type":"code","metadata":{"id":"ckG5OcRGgjyp"},"source":["def evaluate(server_state):\n","  keras_model = create_keras_model()                                              # Creates Keras mode\n","  keras_model.compile(                                                            # Configures the model for training\n","      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  \n","  )\n","  keras_model.set_weights(server_state)                                           # Sets the weights of model same as the server_state\n","  keras_model.evaluate(central_emnist_test)                                       # Returns the loss value & metrics values for the model in test mode.\n","                                                                                  # Computation is done in batch, if batch size not secified, 32 is default value"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qg-YljHEo9bG"},"source":["server_state = federated_algorithm.initialize()\n","evaluate(server_state)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kX-JjFopqtZ"},"source":["for round in range(15):\n","  server_state = federated_algorithm.next(server_state, federated_train_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iawhNljhpjMc"},"source":["evaluate(server_state)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pv6IQRKwqZPl"},"source":["# **Challenge:**\n","\n","1. Implement a version of `server_update` that updates the server weights to be the midpoint of model_weights and mean_client_weights. (Note: This kind of \"midpoint\" approach is analogous to recent work on the [Lookahead optimizer](https://arxiv.org/abs/1907.08610)!).  \n","2. Add [gradient clipping](https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48) to the `client_update` function.\n","3. Implement Federated Averaging with learning rate decay on the clients.\n","  \n","  We could have the server store and broadcast more data. For example, the server could also store the client learning rate, and make it decay over time! Note that this will require changes to the type signatures used in the `tff.tf_computation` calls above.\n","\n","For ideas (including the answer to the harder challenge above) you can see the source-code for [`tff.learning.build_federated_averaging_process`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/build_federated_averaging_process), or check out various [research projects](https://github.com/google-research/federated) using TFF.\n"]}]}