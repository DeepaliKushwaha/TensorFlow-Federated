{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Federated Learning for Image Classigfication.ipynb","private_outputs":true,"provenance":[{"file_id":"1OrIaYUn6S7Yfcbn-rop03NzZ_Fb1hWeZ","timestamp":1623668346421}],"collapsed_sections":[],"authorship_tag":"ABX9TyNYojDi4A0cnwZrqW5NM5+x"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0vNzW12BdECp"},"source":["# **Setting up environment**"]},{"cell_type":"code","metadata":{"id":"k1GEBvTATmFO"},"source":["!pip install --upgrade --quiet tensorflow-federated"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFCPANNnbfgx"},"source":["import nest_asyncio\n","nest_asyncio.apply()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UVtMAIutV9gI"},"source":["%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqRXK4MEWHj9"},"source":["import collections\n","\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_federated as tff\n","\n","np.random.seed(0)\n","\n","tff.federated_computation(lambda: 'Hello, World!')()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BnpygvIDdMhe"},"source":["# **Input Data**"]},{"cell_type":"markdown","metadata":{"id":"wWXYh6PihNI1"},"source":["## **Loading dataset**"]},{"cell_type":"code","metadata":{"id":"ayFxR0sjWOgz"},"source":["emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"76yeoHK9c-Ng"},"source":["len(emnist_train.client_ids)                                                      # Number of clients ID for training"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W-N3RGrFhFvE"},"source":["emnist_train.element_type_structure                                               # Structure of training dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGWNEiZWnkcz"},"source":["### **Exploring data heterogeneity**"]},{"cell_type":"markdown","metadata":{"id":"dlzHB5yhhJqb"},"source":["**Example data**"]},{"cell_type":"code","metadata":{"id":"2G2cGkxshHhE"},"source":["example_dataset = emnist_train.create_tf_dataset_for_client(\n","    emnist_train.client_ids[0])                                                 # Example data from client with ID 0\n","\n","example_element = next(iter(example_dataset))                                     # The iter() function creates an object which can be iterated one element at a time.\n","                                                                                  # The next() function returns the next item in an iterator.\n","example_element['label'].numpy()                                                  # Label of example data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QtAX9sc1d1zf"},"source":["from matplotlib import pyplot as plt\n","plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')        # Pixel representation in dataset for example data\n","plt.grid(False)\n","_ = plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dNlQ2ctPiJsk"},"source":["**MNIST digits from one client**"]},{"cell_type":"code","metadata":{"id":"L0RDpe2QiMa0"},"source":["figure = plt.figure(figsize=(20, 4))\n","j = 0\n","\n","for example in example_dataset.take(40):                                          # Taking 40 elements from example_dataset\n","  plt.subplot(4, 10, j+1)                                                         # Plotting in a grid of 4 x 10 (Similar to subplot of matlab)\n","  plt.imshow(example['pixels'].numpy(), cmap='gray', aspect='equal')              # Plotting gray scale pixel image with equal aspect\n","  plt.axis('off')\n","  j += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AbMPBWZWnHm1"},"source":["**Number of data elements of each client**"]},{"cell_type":"code","metadata":{"id":"pXog6LVqlzkP"},"source":["# Number of examples per layer for a sample of clients\n","f = plt.figure(figsize=(12, 7))\n","f.suptitle('Label Counts for a Sample of Clients')\n","for i in range(6):                                                                # Taking first 6 client's data\n","  client_dataset = emnist_train.create_tf_dataset_for_client(\n","      emnist_train.client_ids[i])                                                 # Dataset of one client\n","  plot_data = collections.defaultdict(list)                                       # Defaultdict is a container like dictionaries. Unlike dictionary, it never raises a KeyError. It provides a default value for the key that does not exists.\n","  for example in client_dataset:                                                  # Taking each data element in client \"i\"\n","    label = example['label'].numpy()                                              # Find label of the element of one client specific dataset\n","    plot_data[label].append(label)                                                # Append label value () corresponding to the key [] (that is same as label)\n","                                                                                  # Append counts individually per label to make plots more colorful instead of one color per plot.\n","  plt.subplot(2, 3, i+1)\n","  plt.title('Client {}'.format(i))\n","  for j in range(10):                                                             # For each label in client \"i\"\n","    plt.hist(\n","        plot_data[j],\n","        density=False,\n","        bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])                                  # Creates histogram"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KuQyOcrWFHMX"},"source":["**Mean pixel image for each label per client**"]},{"cell_type":"code","metadata":{"id":"64pBwl4jnpa7"},"source":["for i in range(5):                                                                # Taking first 5 client's data\n","  client_dataset = emnist_train.create_tf_dataset_for_client(\n","      emnist_train.client_ids[i])\n","  plot_data = collections.defaultdict(list)\n","  for example in client_dataset:                                                  # For each data in client \"i\"\n","    plot_data[example['label'].numpy()].append(example['pixels'].numpy())         # Appending pixel information of element corresponding to the key \n","  f = plt.figure(i, figsize=(12, 5))\n","  f.suptitle(\"Client #{}'s Mean Image Per Label\".format(i))\n","  for j in range(10):                                                             # For each label in client \"i\"\n","    mean_img = np.mean(plot_data[j], 0)                                           # Taking mean of the appended info. for label \"j\"\n","    plt.subplot(2, 5, j+1)\n","    plt.imshow(mean_img.reshape((28, 28)))                                        # Reshaping mean_img to original image shape, then plotting it\n","    plt.axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T1Sn2hbLIYh8"},"source":["## **Preprocessing input data**\n","\n","tf.data.Dataset: \n","https://www.tensorflow.org/api_docs/python/tf/data/Dataset"]},{"cell_type":"code","metadata":{"id":"TYa6L9tCHewt"},"source":["NUM_CLIENTS = 10\n","NUM_EPOCHS = 5\n","BATCH_SIZE = 20\n","SHUFFLE_BUFFER = 100\n","PREFETCH_BUFFER = 10\n","\n","def preprocess(dataset):\n","\n","  def batch_format_fn(element):                                                   # Flatten a batch of pixel info and return the features as an OrderedDict.\n","    return collections.OrderedDict(                                               # OrderedDict preserves the order in which the keys are inserted\n","        x=tf.reshape(element['pixels'], [-1, 784]),                               # Reshaping 28x28 matrix info into 784(=28^2) vector\n","        y=tf.reshape(element['label'], [-1, 1]))                                  # Assigning pixel info to x and label info to y\n","\n","  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(                # Repeat over the data set is used to run over several epochs. repeat() data NUM_epochs times \n","      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)                  # shuffle() method randomly shuffles the elements of this dataset. Fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.\n","                                                                                  # batch() method combines consecutive elements of the dataset into batches.\n","                                                                                  # map:\n","                                                                                  # Creates a Dataset that prefetches elements from this dataset. Most dataset input pipelines should end with a call to prefetch. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n","                                                                                  ## methods execute in the order of writing"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_b0kEdELXFy"},"source":["preprocessed_example_dataset = preprocess(example_dataset)                        # preprocessed example_dataset \n","\n","sample_batch = tf.nest.map_structure(lambda x: x.numpy(),                         # map_structure applies func to each entry in structure and returns a new structure.\n","                                     next(iter(preprocessed_example_dataset)))    # lambda x: x.numpy will convert all the values passed in second argument into numpy values\n","\n","sample_batch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4xZB2tpQVf5T"},"source":["## **Converting user's dataset into a list**"]},{"cell_type":"code","metadata":{"id":"8n0Qkb1DU2_k"},"source":["def make_federated_data(client_data, client_ids):                                 # Returns a list containing preprocessed data of each client specified in client_ids\n","  return [\n","      preprocess(client_data.create_tf_dataset_for_client(x))\n","      for x in client_ids\n","  ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z39gs91abfaF"},"source":["# **Choosing Clients**"]},{"cell_type":"code","metadata":{"id":"5457Ge-Ubcfj"},"source":["sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]                           # Sampling first NUM_CLIENTS \n","\n","federated_train_data = make_federated_data(emnist_train, sample_clients)          # Converting the dataset into list of preprocessed data for selected clients\n","\n","print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n","print('First dataset: {d}'.format(d=federated_train_data[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hY3b_D2J_Ugi"},"source":["# **Creating Model with Keras**"]},{"cell_type":"code","metadata":{"id":"Z6ZE5vNt-_QA"},"source":["def create_keras_model():\n","  return tf.keras.models.Sequential([                                             # Sequential model is created\n","      tf.keras.layers.InputLayer(input_shape=(784,)),                             # Input layer consists of 784 inputs\n","      tf.keras.layers.Dense(10, kernel_initializer='zeros'),                      # Layer with 10 nodes and weight matrix initialized to zeros. dense() implements the operation, output = activation(dot(input, kernel) + bias).\n","      tf.keras.layers.Softmax(),                                                  # softmaxed output\n","  ])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UUkXn-o1CM1A"},"source":["from_keras_model: https://www.tensorflow.org/federated/api_docs/python/tff/learning/from_keras_model\n","\n","losses: https://www.tensorflow.org/api_docs/python/tf/keras/losses\n","\n","metrics: https://www.tensorflow.org/api_docs/python/tf/keras/metrics"]},{"cell_type":"code","metadata":{"id":"hahiTO2dB8P0"},"source":["def model_fn():\n","  # We _must_ create a new model here, and _not_ capture it from an external scope. TFF will call this within different graph contexts.\n","  keras_model = create_keras_model()                                              # Model created using keras\n","  return tff.learning.from_keras_model(                                           # Builds a tff.learning.Model object from a tf.keras.Model\n","      keras_model,\n","      input_spec=preprocessed_example_dataset.element_spec,                       # Specifies the type of arguments the model expects. \n","                                                                                  # element_spec() method gives type specification of an element of the dataset.  \n","      loss=tf.keras.losses.SparseCategoricalCrossentropy(),                       # A single tf.keras.losses.Loss or a list of losses-per-output. . \n","                                                                                  # SparseCategoricalCrossentropy() computes the crossentropy loss between the labels and predictions\n","      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])                     # A metric is a function that is used to judge the performance of model.\n","                                                                                  # SparseCategoricalAccuracy: Compute the frequency with which y_pred matches y_true\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c8LW0bF3MNg5"},"source":["# **Training Model on Federated Data**\n","\n","build_federated_averaging_process: https://www.tensorflow.org/federated/api_docs/python/tff/learning/build_federated_averaging_process\n","\n","Optimizers: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"]},{"cell_type":"code","metadata":{"id":"IkI9Mu94MJWB"},"source":["iterative_process = tff.learning.build_federated_averaging_process(               # Builds an iterative process that performs federated averaging\n","    model_fn,                                                                     # A tff.learning.Model.\n","    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),      # Optimizer for client\n","                                                                                  # Optimizing using stochastic gradient descent (SGD) with specified learning rate\n","    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))       # Optimizer for server"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UeEuIxZDPHxz"},"source":["TFF has constructed a pair of federated computations and packaged them into a `tff.templates.IterativeProcess` in which these computations are available as a pair of properties `initialize` and `next`.\n","\n","### `Initialize`"]},{"cell_type":"code","metadata":{"id":"2Hu72OpjOaGb"},"source":["str(iterative_process.initialize.type_signature)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1hCQtt1Qb5v"},"source":["state = iterative_process.initialize()                                            # Initializes computation to construct the server state."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dg9XjnQfQay9"},"source":["### `Next`"]},{"cell_type":"code","metadata":{"id":"LqWcadk-05wi"},"source":["state, metrics = iterative_process.next(state, federated_train_data)              # It's first argument is the current state (originally produced by `tff.templates.IterativeProcess.initialize`), and the first (or only) returned value is the updated state. \n","print('round  1, metrics={}'.format(metrics))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eaIY0zmtxoLz"},"source":["NUM_ROUNDS = 11\n","for round_num in range(2, NUM_ROUNDS):                                            # Running multiple rounds of server training.\n","  state, metrics = iterative_process.next(state, federated_train_data)            # Same users are used for each round as federated_train_data is same at each round\n","  print('round {:2d}, metrics={}'.format(round_num, metrics))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wYxTk4z-2FOt"},"source":["# **Displaying model metrics in TensorBoard**"]},{"cell_type":"code","metadata":{"id":"P03tTfK0xwG4"},"source":["#@test {\"skip\": true}\n","logdir = \"/tmp/logs/scalars/training/\"                                            # The directory to write an event file\n","summary_writer = tf.summary.create_file_writer(logdir)                            # Creates a summary file writer for the given log directory.\n","state = iterative_process.initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1aJUGMG-2n5n"},"source":["#@test {\"skip\": true}\n","with summary_writer.as_default():                                                 # with statement is used in exception handling. It helps avoiding bugs and leaks by ensuring that a resource is properly released when the code using the resource is completely executed.\n","  for round_num in range(1, NUM_ROUNDS):                                          # NUM_ROUNDS of server training\n","    state, metrics = iterative_process.next(state, federated_train_data)          # Each round of training\n","    for name, value in metrics['train'].items():                                  # metrics['train']= OrderedDict([('sparse_categorical_accuracy', 0.6872428), ('loss', 1.0891807)])\n","      tf.summary.scalar(name, value, step=round_num)                              # Writes scalar \"value\" corresponding to \"name\" metric "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKNQ4ROc2sDf"},"source":["#@test {\"skip\": true}\n","!ls {logdir}\n","%tensorboard --logdir {logdir} --port=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iWAP-U7m2-1t"},"source":["# @test {\"skip\": true}\n","# Uncomment and run this this cell to clean your directory of old output for\n","# future graphs from this directory. We don't run it by default so that if \n","# you do a \"Runtime > Run all\" you don't lose your results.\n","\n","#!rm -R /tmp/logs/scalars/*"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BezssGXG3qrm"},"source":["# **Customizing the Model Implementation**"]},{"cell_type":"markdown","metadata":{"id":"Vg81d8emObzm"},"source":["## **Defining model variables, forward pass, and metrics**\n"]},{"cell_type":"code","metadata":{"id":"--4c3P1g2IyK"},"source":[" MnistVariables = collections.namedtuple(                                         # function for creating tuple subclasses with named fields\n","    'MnistVariables', 'weights bias num_examples loss_sum accuracy_sum')          "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e2H9u2rMmVd-"},"source":["### Function for creating variables\n"]},{"cell_type":"code","metadata":{"id":"OjKtQ22v4BLP"},"source":["def create_mnist_variables():                                                     # Function to create the variables.\n","  return MnistVariables(\n","      weights=tf.Variable(                                                        # Defining variable for weights\n","          lambda: tf.zeros(dtype=tf.float32, shape=(784, 10)),                    # Initializing weights to be zero of size 784 x 10 and as float variable\n","          name='weights',                                                         # Assigning name to the variable\n","          trainable=True),                                                        # \n","      bias=tf.Variable(                                                           # Defining variable for bias\n","          lambda: tf.zeros(dtype=tf.float32, shape=(10)),\n","          name='bias',\n","          trainable=True),\n","      num_examples=tf.Variable(0.0, name='num_examples', trainable=False),        # Defining variable for number of examples\n","      loss_sum=tf.Variable(0.0, name='loss_sum', trainable=False),                # Defining variable for loss\n","      accuracy_sum=tf.Variable(0.0, name='accuracy_sum', trainable=False))        # Defining variable for accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D8M8IcvAuDao"},"source":["### Function for predicting labels, computing loss and accuracy in a forward pass"]},{"cell_type":"code","metadata":{"id":"ZwHwk3LNmkG7"},"source":["def mnist_forward_pass(variables, batch):                                         # Forward pass method that computes loss and updates the cumulative statistics for a single batch of input data\n","  y = tf.nn.softmax(tf.matmul(batch['x'], variables.weights) + variables.bias)    # NN output, computes softmax activations.\n","  predictions = tf.cast(tf.argmax(y, 1), tf.int32)                                # NN prediction, assigns the location of vector y, corresponding to largest value and casts that value into 32 bit integer\n","\n","  flat_labels = tf.reshape(batch['y'], [-1])                                      # Reshapes batch['y'] into a vector (second argument defines the shape of final tensor and [-1] means vector)\n","  loss = -tf.reduce_mean(                                                         # Computes mean of the tensor across columns\n","      tf.reduce_sum(tf.one_hot(flat_labels, 10) * tf.math.log(y), axis=[1]))      # Sums the dot product of one hot vector of length 10, with indices specified by \"flat_labels\" and the predicted labels\n","  accuracy = tf.reduce_mean(\n","      tf.cast(tf.equal(predictions, flat_labels), tf.float32))                    # tf.equal() returns a boolean value after comparing the values \n","\n","  num_examples = tf.cast(tf.size(batch['y']), tf.float32)                         # Number of examples assigned to the size of the output values\n","\n","  variables.num_examples.assign_add(num_examples)                                 # Adds the new value to the varibles\n","  variables.loss_sum.assign_add(loss * num_examples)\n","  variables.accuracy_sum.assign_add(accuracy * num_examples)\n","\n","  return loss, predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dej_0wNVuU2B"},"source":["### Function for returning local metrics"]},{"cell_type":"code","metadata":{"id":"CBkTxvhztwk3"},"source":["def get_local_mnist_metrics(variables):\n","  return collections.OrderedDict(\n","      num_examples=variables.num_examples,\n","      loss=variables.loss_sum / variables.num_examples,\n","      accuracy=variables.accuracy_sum / variables.num_examples)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W-Vwj4iI1-ZY"},"source":["### Function for aggregrating local metrics"]},{"cell_type":"code","metadata":{"id":"0IMVGi_fucoj"},"source":["@tff.federated_computation\n","def aggregate_mnist_metrics_across_clients(metrics):\n","  return collections.OrderedDict(\n","      num_examples=tff.federated_sum(metrics.num_examples),                       # Computes a sum at tff.SERVER of a value placed on the tff.CLIENTS.\n","      loss=tff.federated_mean(metrics.loss, metrics.num_examples),                # Computes a mean of value . It can also compute sum based on different weights. Read: https://www.tensorflow.org/federated/api_docs/python/tff/federated_mean\n","      accuracy=tff.federated_mean(metrics.accuracy, metrics.num_examples))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZAwRgbZ7-FyN"},"source":["### Constructing an instance of `tff.learning.Model`"]},{"cell_type":"code","metadata":{"id":"CPaJZP2y-6O-"},"source":["class MnistModel(tff.learning.Model):\n","\n","  def __init__(self):\n","    self._variables = create_mnist_variables()                                    # Calling variable declaration function\n","\n","  @property                                                                       # \n","  def trainable_variables(self):                                                  # Returns a list of trainable variables\n","    return [self._variables.weights, self._variables.bias]                        \n","\n","  @property\n","  def non_trainable_variables(self):                                              # Returns an empty list\n","    return []\n","\n","  @property\n","  def local_variables(self):                                                      # Returns local metrics\n","    return [\n","        self._variables.num_examples, self._variables.loss_sum,\n","        self._variables.accuracy_sum\n","    ]\n","\n","  @property\n","  def input_spec(self):                                                           # Returns specification of input\n","    return collections.OrderedDict(\n","        x=tf.TensorSpec([None, 784], tf.float32),                                 # tf.TensorSpec \n","        y=tf.TensorSpec([None, 1], tf.int32))\n","\n","  @tf.function\n","  def forward_pass(self, batch, training=True):\n","    del training                                                                  # deletes variable \"training\"\n","    loss, predictions = mnist_forward_pass(self._variables, batch)                \n","    num_exmaples = tf.shape(batch['x'])[0]\n","    return tff.learning.BatchOutput(                                              # A structure that holds the output of a tff.learning.Model.\n","        loss=loss, predictions=predictions, num_examples=num_exmaples)\n","\n","  @tf.function\n","  def report_local_outputs(self):\n","    return get_local_mnist_metrics(self._variables)                               # Returns local metrics \n","\n","  @property\n","  def federated_output_computation(self):                                         # Returns aggregated model metrics\n","    return aggregate_mnist_metrics_across_clients"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4L5A366w8uA0"},"source":["### Simulating federated training with the new model"]},{"cell_type":"code","metadata":{"id":"RibyvExm8V6U"},"source":["iterative_process = tff.learning.build_federated_averaging_process(               # Builds an iterative process that performs federated averaging\n","    MnistModel,\n","    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"knksl9qi88Vt"},"source":["state = iterative_process.initialize()                                            # Initializes computation to construct the server state."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ja3Wrjys9AiL"},"source":["for round_num in range(1, 11):\n","  state, metrics = iterative_process.next(state, federated_train_data)\n","  print('round {:2d}, metrics={}'.format(round_num, metrics))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NB5e4M5493Ih"},"source":["#@test {\"skip\": true}\n","logdir = \"/tmp/logs/scalars/training/\"                                            # The directory to write an event file\n","summary_writer = tf.summary.create_file_writer(logdir)                            # Creates a summary file writer for the given log directory.\n","state = iterative_process.initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WkuC_iKw-NOY"},"source":["#@test {\"skip\": true}\n","with summary_writer.as_default():                                                 # with statement is used in exception handling. It helps avoiding bugs and leaks by ensuring that a resource is properly released when the code using the resource is completely executed.\n","  for round_num in range(1, NUM_ROUNDS):                                          # NUM_ROUNDS of server training\n","    state, metrics = iterative_process.next(state, federated_train_data)          # Each round of training\n","    for name, value in metrics['train'].items():                                  # metrics['train']= OrderedDict([('sparse_categorical_accuracy', 0.6872428), ('loss', 1.0891807)])\n","      tf.summary.scalar(name, value, step=round_num)                              # Writes scalar \"value\" corresponding to \"name\" metric "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hnpXzEB1-Q2z"},"source":["#@test {\"skip\": true}\n","!ls {logdir}\n","%tensorboard --logdir {logdir} --port=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rHsDsKB-UYv"},"source":["# @test {\"skip\": true}\n","# Uncomment and run this this cell to clean your directory of old output for\n","# future graphs from this directory. We don't run it by default so that if \n","# you do a \"Runtime > Run all\" you don't lose your results.\n","\n","#!rm -R /tmp/logs/scalars/*"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UdOnS14jA3eu"},"source":["### Evaluation"]},{"cell_type":"code","metadata":{"id":"vRdXpJPSBjha"},"source":["evaluation = tff.learning.build_federated_evaluation(MnistModel)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AoToj_qeBusS"},"source":["str(evaluation.type_signature)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y4-JPhfxBupx"},"source":["train_metrics = evaluation(state.model, federated_train_data)\n","str(train_metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2SrpAHVyDtLV"},"source":["### Evaluation of test dataset"]},{"cell_type":"code","metadata":{"id":"ioss8BH4D07e"},"source":["federated_test_data = make_federated_data(emnist_test, sample_clients)\n","len(federated_test_data), federated_test_data[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSQHcJD8DYBJ"},"source":["test_metrics = evaluation(state.model, federated_test_data)\n","str(test_metrics)"],"execution_count":null,"outputs":[]}]}